{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> Perceptron Algorithm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p</th>\n",
       "      <th>q</th>\n",
       "      <th>correctly_classified</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.78051</td>\n",
       "      <td>-0.063669</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.28774</td>\n",
       "      <td>0.291390</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.40714</td>\n",
       "      <td>0.178780</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.29230</td>\n",
       "      <td>0.421700</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.50922</td>\n",
       "      <td>0.352560</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         p         q  correctly_classified\n",
       "0  0.78051 -0.063669                     1\n",
       "1  0.28774  0.291390                     1\n",
       "2  0.40714  0.178780                     1\n",
       "3  0.29230  0.421700                     1\n",
       "4  0.50922  0.352560                     1"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_csv(\"../data/perceptron_algorithm_data.csv\", header = None)\n",
    "train_data.columns = [\"p\", \"q\", \"correctly_classified\"]\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p</th>\n",
       "      <th>q</th>\n",
       "      <th>correctly_classified</th>\n",
       "      <th>X</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.55330</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>(0.5533, 1.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>0.44274</td>\n",
       "      <td>0.59205</td>\n",
       "      <td>0</td>\n",
       "      <td>(0.44273999999999997, 0.59205)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>0.85176</td>\n",
       "      <td>0.66120</td>\n",
       "      <td>0</td>\n",
       "      <td>(0.8517600000000001, 0.6612)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>0.60436</td>\n",
       "      <td>0.86605</td>\n",
       "      <td>0</td>\n",
       "      <td>(0.60436, 0.86605)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>0.68243</td>\n",
       "      <td>0.48301</td>\n",
       "      <td>0</td>\n",
       "      <td>(0.68243, 0.48301000000000005)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.76815</td>\n",
       "      <td>0</td>\n",
       "      <td>(1.0, 0.76815)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>0.72989</td>\n",
       "      <td>0.81070</td>\n",
       "      <td>0</td>\n",
       "      <td>(0.7298899999999999, 0.8107)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>0.67377</td>\n",
       "      <td>0.77975</td>\n",
       "      <td>0</td>\n",
       "      <td>(0.67377, 0.77975)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>0.78761</td>\n",
       "      <td>0.58177</td>\n",
       "      <td>0</td>\n",
       "      <td>(0.78761, 0.58177)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>0.71442</td>\n",
       "      <td>0.76680</td>\n",
       "      <td>0</td>\n",
       "      <td>(0.7144199999999999, 0.7668)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0.49379</td>\n",
       "      <td>0.54226</td>\n",
       "      <td>0</td>\n",
       "      <td>(0.49378999999999995, 0.5422600000000001)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>0.78974</td>\n",
       "      <td>0.74233</td>\n",
       "      <td>0</td>\n",
       "      <td>(0.78974, 0.74233)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>0.67905</td>\n",
       "      <td>0.60921</td>\n",
       "      <td>0</td>\n",
       "      <td>(0.67905, 0.60921)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>0.66420</td>\n",
       "      <td>0.72519</td>\n",
       "      <td>0</td>\n",
       "      <td>(0.6642, 0.72519)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>0.79396</td>\n",
       "      <td>0.56789</td>\n",
       "      <td>0</td>\n",
       "      <td>(0.79396, 0.56789)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>0.70758</td>\n",
       "      <td>0.76022</td>\n",
       "      <td>0</td>\n",
       "      <td>(0.70758, 0.76022)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>0.59421</td>\n",
       "      <td>0.61857</td>\n",
       "      <td>0</td>\n",
       "      <td>(0.59421, 0.61857)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>0.49364</td>\n",
       "      <td>0.56224</td>\n",
       "      <td>0</td>\n",
       "      <td>(0.49363999999999997, 0.56224)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>0.77707</td>\n",
       "      <td>0.35025</td>\n",
       "      <td>0</td>\n",
       "      <td>(0.7770699999999999, 0.35025)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>0.79785</td>\n",
       "      <td>0.76921</td>\n",
       "      <td>0</td>\n",
       "      <td>(0.79785, 0.7692100000000001)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>0.70876</td>\n",
       "      <td>0.96764</td>\n",
       "      <td>0</td>\n",
       "      <td>(0.7087600000000001, 0.96764)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>0.69176</td>\n",
       "      <td>0.60865</td>\n",
       "      <td>0</td>\n",
       "      <td>(0.69176, 0.60865)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>0.66408</td>\n",
       "      <td>0.92075</td>\n",
       "      <td>0</td>\n",
       "      <td>(0.66408, 0.92075)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>0.65973</td>\n",
       "      <td>0.66666</td>\n",
       "      <td>0</td>\n",
       "      <td>(0.65973, 0.66666)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>0.64574</td>\n",
       "      <td>0.56845</td>\n",
       "      <td>0</td>\n",
       "      <td>(0.64574, 0.56845)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>0.89639</td>\n",
       "      <td>0.70850</td>\n",
       "      <td>0</td>\n",
       "      <td>(0.8963899999999999, 0.7085)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>0.85476</td>\n",
       "      <td>0.63167</td>\n",
       "      <td>0</td>\n",
       "      <td>(0.8547600000000001, 0.63167)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>0.62091</td>\n",
       "      <td>0.80424</td>\n",
       "      <td>0</td>\n",
       "      <td>(0.6209100000000001, 0.80424)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>0.79057</td>\n",
       "      <td>0.56108</td>\n",
       "      <td>0</td>\n",
       "      <td>(0.79057, 0.56108)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>0.58935</td>\n",
       "      <td>0.71582</td>\n",
       "      <td>0</td>\n",
       "      <td>(0.58935, 0.71582)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>0.56846</td>\n",
       "      <td>0.74060</td>\n",
       "      <td>0</td>\n",
       "      <td>(0.5684600000000001, 0.7406)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>0.65912</td>\n",
       "      <td>0.71548</td>\n",
       "      <td>0</td>\n",
       "      <td>(0.6591199999999999, 0.71548)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>0.70938</td>\n",
       "      <td>0.74041</td>\n",
       "      <td>0</td>\n",
       "      <td>(0.70938, 0.74041)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>0.59154</td>\n",
       "      <td>0.62927</td>\n",
       "      <td>0</td>\n",
       "      <td>(0.59154, 0.62927)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>0.45829</td>\n",
       "      <td>0.46410</td>\n",
       "      <td>0</td>\n",
       "      <td>(0.45829, 0.4641)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>0.79982</td>\n",
       "      <td>0.74847</td>\n",
       "      <td>0</td>\n",
       "      <td>(0.79982, 0.74847)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>0.60974</td>\n",
       "      <td>0.54757</td>\n",
       "      <td>0</td>\n",
       "      <td>(0.60974, 0.54757)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>0.68127</td>\n",
       "      <td>0.86985</td>\n",
       "      <td>0</td>\n",
       "      <td>(0.6812699999999999, 0.86985)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>0.76694</td>\n",
       "      <td>0.64736</td>\n",
       "      <td>0</td>\n",
       "      <td>(0.76694, 0.64736)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>0.69048</td>\n",
       "      <td>0.83058</td>\n",
       "      <td>0</td>\n",
       "      <td>(0.69048, 0.8305799999999999)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>0.68122</td>\n",
       "      <td>0.96541</td>\n",
       "      <td>0</td>\n",
       "      <td>(0.6812199999999999, 0.96541)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>0.73229</td>\n",
       "      <td>0.64245</td>\n",
       "      <td>0</td>\n",
       "      <td>(0.73229, 0.64245)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>0.76145</td>\n",
       "      <td>0.60138</td>\n",
       "      <td>0</td>\n",
       "      <td>(0.76145, 0.60138)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>0.58985</td>\n",
       "      <td>0.86955</td>\n",
       "      <td>0</td>\n",
       "      <td>(0.58985, 0.86955)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>0.73145</td>\n",
       "      <td>0.74516</td>\n",
       "      <td>0</td>\n",
       "      <td>(0.73145, 0.74516)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.77029</td>\n",
       "      <td>0.70140</td>\n",
       "      <td>0</td>\n",
       "      <td>(0.7702899999999999, 0.7014)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.73156</td>\n",
       "      <td>0.71782</td>\n",
       "      <td>0</td>\n",
       "      <td>(0.73156, 0.71782)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.44556</td>\n",
       "      <td>0.57991</td>\n",
       "      <td>0</td>\n",
       "      <td>(0.44556, 0.57991)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.85275</td>\n",
       "      <td>0.85987</td>\n",
       "      <td>0</td>\n",
       "      <td>(0.85275, 0.85987)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.51912</td>\n",
       "      <td>0.62359</td>\n",
       "      <td>0</td>\n",
       "      <td>(0.51912, 0.62359)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          p        q  correctly_classified  \\\n",
       "50  0.55330  1.00000                     0   \n",
       "51  0.44274  0.59205                     0   \n",
       "52  0.85176  0.66120                     0   \n",
       "53  0.60436  0.86605                     0   \n",
       "54  0.68243  0.48301                     0   \n",
       "55  1.00000  0.76815                     0   \n",
       "56  0.72989  0.81070                     0   \n",
       "57  0.67377  0.77975                     0   \n",
       "58  0.78761  0.58177                     0   \n",
       "59  0.71442  0.76680                     0   \n",
       "60  0.49379  0.54226                     0   \n",
       "61  0.78974  0.74233                     0   \n",
       "62  0.67905  0.60921                     0   \n",
       "63  0.66420  0.72519                     0   \n",
       "64  0.79396  0.56789                     0   \n",
       "65  0.70758  0.76022                     0   \n",
       "66  0.59421  0.61857                     0   \n",
       "67  0.49364  0.56224                     0   \n",
       "68  0.77707  0.35025                     0   \n",
       "69  0.79785  0.76921                     0   \n",
       "70  0.70876  0.96764                     0   \n",
       "71  0.69176  0.60865                     0   \n",
       "72  0.66408  0.92075                     0   \n",
       "73  0.65973  0.66666                     0   \n",
       "74  0.64574  0.56845                     0   \n",
       "75  0.89639  0.70850                     0   \n",
       "76  0.85476  0.63167                     0   \n",
       "77  0.62091  0.80424                     0   \n",
       "78  0.79057  0.56108                     0   \n",
       "79  0.58935  0.71582                     0   \n",
       "80  0.56846  0.74060                     0   \n",
       "81  0.65912  0.71548                     0   \n",
       "82  0.70938  0.74041                     0   \n",
       "83  0.59154  0.62927                     0   \n",
       "84  0.45829  0.46410                     0   \n",
       "85  0.79982  0.74847                     0   \n",
       "86  0.60974  0.54757                     0   \n",
       "87  0.68127  0.86985                     0   \n",
       "88  0.76694  0.64736                     0   \n",
       "89  0.69048  0.83058                     0   \n",
       "90  0.68122  0.96541                     0   \n",
       "91  0.73229  0.64245                     0   \n",
       "92  0.76145  0.60138                     0   \n",
       "93  0.58985  0.86955                     0   \n",
       "94  0.73145  0.74516                     0   \n",
       "95  0.77029  0.70140                     0   \n",
       "96  0.73156  0.71782                     0   \n",
       "97  0.44556  0.57991                     0   \n",
       "98  0.85275  0.85987                     0   \n",
       "99  0.51912  0.62359                     0   \n",
       "\n",
       "                                            X  \n",
       "50                              (0.5533, 1.0)  \n",
       "51             (0.44273999999999997, 0.59205)  \n",
       "52               (0.8517600000000001, 0.6612)  \n",
       "53                         (0.60436, 0.86605)  \n",
       "54             (0.68243, 0.48301000000000005)  \n",
       "55                             (1.0, 0.76815)  \n",
       "56               (0.7298899999999999, 0.8107)  \n",
       "57                         (0.67377, 0.77975)  \n",
       "58                         (0.78761, 0.58177)  \n",
       "59               (0.7144199999999999, 0.7668)  \n",
       "60  (0.49378999999999995, 0.5422600000000001)  \n",
       "61                         (0.78974, 0.74233)  \n",
       "62                         (0.67905, 0.60921)  \n",
       "63                          (0.6642, 0.72519)  \n",
       "64                         (0.79396, 0.56789)  \n",
       "65                         (0.70758, 0.76022)  \n",
       "66                         (0.59421, 0.61857)  \n",
       "67             (0.49363999999999997, 0.56224)  \n",
       "68              (0.7770699999999999, 0.35025)  \n",
       "69              (0.79785, 0.7692100000000001)  \n",
       "70              (0.7087600000000001, 0.96764)  \n",
       "71                         (0.69176, 0.60865)  \n",
       "72                         (0.66408, 0.92075)  \n",
       "73                         (0.65973, 0.66666)  \n",
       "74                         (0.64574, 0.56845)  \n",
       "75               (0.8963899999999999, 0.7085)  \n",
       "76              (0.8547600000000001, 0.63167)  \n",
       "77              (0.6209100000000001, 0.80424)  \n",
       "78                         (0.79057, 0.56108)  \n",
       "79                         (0.58935, 0.71582)  \n",
       "80               (0.5684600000000001, 0.7406)  \n",
       "81              (0.6591199999999999, 0.71548)  \n",
       "82                         (0.70938, 0.74041)  \n",
       "83                         (0.59154, 0.62927)  \n",
       "84                          (0.45829, 0.4641)  \n",
       "85                         (0.79982, 0.74847)  \n",
       "86                         (0.60974, 0.54757)  \n",
       "87              (0.6812699999999999, 0.86985)  \n",
       "88                         (0.76694, 0.64736)  \n",
       "89              (0.69048, 0.8305799999999999)  \n",
       "90              (0.6812199999999999, 0.96541)  \n",
       "91                         (0.73229, 0.64245)  \n",
       "92                         (0.76145, 0.60138)  \n",
       "93                         (0.58985, 0.86955)  \n",
       "94                         (0.73145, 0.74516)  \n",
       "95               (0.7702899999999999, 0.7014)  \n",
       "96                         (0.73156, 0.71782)  \n",
       "97                         (0.44556, 0.57991)  \n",
       "98                         (0.85275, 0.85987)  \n",
       "99                         (0.51912, 0.62359)  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[train_data[\"correctly_classified\"]==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[\"X\"] = tuple(zip(train_data[\"p\"], train_data[\"q\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p</th>\n",
       "      <th>q</th>\n",
       "      <th>correctly_classified</th>\n",
       "      <th>X</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.78051</td>\n",
       "      <td>-0.063669</td>\n",
       "      <td>1</td>\n",
       "      <td>(0.78051, -0.063669)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.28774</td>\n",
       "      <td>0.291390</td>\n",
       "      <td>1</td>\n",
       "      <td>(0.28774, 0.29139)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.40714</td>\n",
       "      <td>0.178780</td>\n",
       "      <td>1</td>\n",
       "      <td>(0.40714, 0.17878)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.29230</td>\n",
       "      <td>0.421700</td>\n",
       "      <td>1</td>\n",
       "      <td>(0.2923, 0.4217)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.50922</td>\n",
       "      <td>0.352560</td>\n",
       "      <td>1</td>\n",
       "      <td>(0.50922, 0.35256)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.77029</td>\n",
       "      <td>0.701400</td>\n",
       "      <td>0</td>\n",
       "      <td>(0.7702899999999999, 0.7014)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.73156</td>\n",
       "      <td>0.717820</td>\n",
       "      <td>0</td>\n",
       "      <td>(0.73156, 0.71782)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.44556</td>\n",
       "      <td>0.579910</td>\n",
       "      <td>0</td>\n",
       "      <td>(0.44556, 0.57991)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.85275</td>\n",
       "      <td>0.859870</td>\n",
       "      <td>0</td>\n",
       "      <td>(0.85275, 0.85987)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.51912</td>\n",
       "      <td>0.623590</td>\n",
       "      <td>0</td>\n",
       "      <td>(0.51912, 0.62359)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          p         q  correctly_classified                             X\n",
       "0   0.78051 -0.063669                     1          (0.78051, -0.063669)\n",
       "1   0.28774  0.291390                     1            (0.28774, 0.29139)\n",
       "2   0.40714  0.178780                     1            (0.40714, 0.17878)\n",
       "3   0.29230  0.421700                     1              (0.2923, 0.4217)\n",
       "4   0.50922  0.352560                     1            (0.50922, 0.35256)\n",
       "..      ...       ...                   ...                           ...\n",
       "95  0.77029  0.701400                     0  (0.7702899999999999, 0.7014)\n",
       "96  0.73156  0.717820                     0            (0.73156, 0.71782)\n",
       "97  0.44556  0.579910                     0            (0.44556, 0.57991)\n",
       "98  0.85275  0.859870                     0            (0.85275, 0.85987)\n",
       "99  0.51912  0.623590                     0            (0.51912, 0.62359)\n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting the random seed, feel free to change it and see different solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define step and prediction functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stepFunction(t):\n",
    "    if t >= 0:\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "\n",
    "def prediction(X, W, b):\n",
    "    return stepFunction((np.matmul(X, W) + b)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([(3,9), (2,2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = [[1,2], [3,3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([(3,9), (2,2)])\n",
    "W = np.array([(1,2), (3,3)]).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3, 9],\n",
       "       [2, 2]])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 3],\n",
       "       [2, 3]])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[21, 36],\n",
       "       [ 6, 12]])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.matmul(X,W)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the perceptronStep function to implement the Perceptron Trick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The function should receive as inputs the data X, the labels y,\n",
    "# the weights W (as an array), and the bias b,\n",
    "# update the weights and bias W, b, according to the perceptron algorithm,\n",
    "# and return W and b.\n",
    "def perceptronStep(X, y, W, b, learn_rate=0.01):\n",
    "    for x, y_val, w, b in zip(X, y, W, b):\n",
    "        if y_val == 0:\n",
    "            w[0] += learn_rate*x[0]\n",
    "            w[1] += learn_rate*x[1]\n",
    "            b_val += learn_rate\n",
    "        else:\n",
    "            w[0] -= learn_rate*x[0]\n",
    "            w[1] -= learn_rate*x[1]\n",
    "            b_val -= learn_rate\n",
    "    return W, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-32-65728ff619e4>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-32-65728ff619e4>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    perceptronStep([], [0, 1], W, b, learn_rate=0.01):\u001b[0m\n\u001b[0m                                                      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "perceptronStep([], [0, 1], W, b, learn_rate=0.01):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This function runs the perceptron algorithm repeatedly on the dataset, and returns a few of the boundary lines obtained in the iterations, for plotting purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feel free to play with the learning rate and the num_epochs,\n",
    "# and see your results plotted below.\n",
    "def trainPerceptronAlgorithm(X, y, learn_rate=0.01, num_epochs=25):\n",
    "    x_min, x_max = min(X.T[0]), max(X.T[0])\n",
    "    y_min, y_max = min(X.T[1]), max(X.T[1])\n",
    "    W = np.array(np.random.rand(2, 1))\n",
    "    b = np.random.rand(1)[0] + x_max\n",
    "    # These are the solution lines that get plotted below.\n",
    "    boundary_lines = []\n",
    "    for i in range(num_epochs):\n",
    "        # In each epoch, we apply the perceptron step.\n",
    "        W, b = perceptronStep(X, y, W, b, learn_rate)\n",
    "        boundary_lines.append((-W[0] / W[1], -b / W[1]))\n",
    "    return boundary_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "udacity3.8",
   "language": "python",
   "name": "udacity3.8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
